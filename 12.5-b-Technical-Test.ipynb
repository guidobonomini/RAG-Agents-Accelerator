{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6423f8f3-a592-4ee7-9969-39e38933be52",
   "metadata": {},
   "source": [
    "# Technical Test - KSG - Guido Bonomini\n",
    "## Creating a Weather Agent using a TemperatureTool and a CoordinatesTool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf854d-94d7-4a65-952a-22c7999a9a9b",
   "metadata": {},
   "source": [
    "### Step-by-Step Overview\n",
    "This notebook consists of four main sections:\n",
    "\n",
    "- Prep work for creating the ReaderTool:\n",
    "    - Upload the Constitution.zip into the Blob Container\n",
    "    - Create indexes for the Constitution book\n",
    "    - Test indexes\n",
    "\n",
    "- Setting up two MCP Servers (Flask) each providing a unique functionality:\n",
    "\n",
    "    - A Reader Server returns the information on the uploaded pdf files.\n",
    "\n",
    "    - A Infoleg Server that returns the Infoleg (Argentina Ministry of Justice) website.\n",
    "\n",
    "- Creating LangChain Tools: These tools allow our AI agent to interact seamlessly with the MCP servers we just built.\n",
    "\n",
    "- Building the AI Agent with LangChain: Using LangChain's React agent framework, we'll set up an intelligent AI agent to leverage our custom tools.\n",
    "\n",
    "- Testing the Weather Agent: Finally, we'll run queries through the agent and observe its responses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d73b983",
   "metadata": {},
   "source": [
    "### Step 1. Setup code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import random\n",
    "import uuid\n",
    "import shutil\n",
    "import zipfile\n",
    "from collections import OrderedDict\n",
    "import urllib.request\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from langchain_core.runnables import ConfigurableField\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "from common.utils import upload_file_to_blob, extract_zip_file, upload_directory_to_blob\n",
    "from common.utils import parse_pdf, read_pdf_files\n",
    "from common.prompts import DOCSEARCH_PROMPT_TEXT\n",
    "from common.utils import CustomAzureSearchRetriever\n",
    "\n",
    "\n",
    "from IPython.display import Markdown, HTML, display  \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "def printmd(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78927a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ENV variables that Langchain needs to connect to Azure OpenAI\n",
    "os.environ[\"OPENAI_API_VERSION\"] = os.environ[\"AZURE_OPENAI_API_VERSION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54a1e53",
   "metadata": {},
   "source": [
    "#### Upload book to Blob Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd27c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Define connection string and other parameters\n",
    "BLOB_CONTAINER_NAME = \"books\"\n",
    "BLOB_NAME = \"constitution.zip\"\n",
    "LOCAL_FILE_PATH = \"./data/\" + BLOB_NAME  # Path to the local file you want to upload\n",
    "upload_directory = \"./data/temp_extract\"  # Temporary directory to extract the zip file\n",
    "\n",
    "# Extract the zip file\n",
    "extract_zip_file(LOCAL_FILE_PATH, upload_directory)\n",
    "\n",
    "# Upload the extracted files and folder structure\n",
    "upload_directory_to_blob(upload_directory, BLOB_CONTAINER_NAME)\n",
    "\n",
    "# Clean up: Optionally, you can remove the temp folder after uploading\n",
    "shutil.rmtree(upload_directory)\n",
    "print(f\"Temp Folder: {upload_directory} removed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf0cfda7",
   "metadata": {},
   "source": [
    "#### Manual Document Cracking with Push to Vector-based Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2bc560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the parsed data for each book\n",
    "book_pages_map = dict()\n",
    "\n",
    "# Open the zip file\n",
    "with zipfile.ZipFile(LOCAL_FILE_PATH, 'r') as zip_ref:\n",
    "    # Iterate over the PDF files inside the zip archive\n",
    "    for file_info in zip_ref.infolist():\n",
    "        if file_info.filename.endswith('.pdf'):\n",
    "            book = file_info.filename\n",
    "            \n",
    "            print(\"Extracting Text from\", book, \"...\")\n",
    "            \n",
    "            # Read the PDF file directly into memory (as a binary stream)\n",
    "            with zip_ref.open(file_info) as file:\n",
    "                file_stream = io.BytesIO(file.read())  # Convert file to BytesIO for in-memory file handling\n",
    "\n",
    "                # Capture the start time\n",
    "                start_time = time.time()\n",
    "\n",
    "                # Parse the PDF (you would use your actual parse_pdf function here)\n",
    "                book_map = parse_pdf(file_stream, form_recognizer=False, verbose=True)\n",
    "                book_pages_map[book] = book_map\n",
    "                \n",
    "                # Capture the end time and calculate the elapsed time\n",
    "                end_time = time.time()\n",
    "                elapsed_time = end_time - start_time\n",
    "\n",
    "                print(f\"Parsing took: {elapsed_time:.6f} seconds\")\n",
    "                print(f\"{book} contained {len(book_map)} pages\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ef0019",
   "metadata": {},
   "source": [
    "#### Create the Laws Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f0c71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 75\n",
    "embedder = AzureOpenAIEmbeddings(deployment=os.environ[\"EMBEDDING_DEPLOYMENT_NAME\"], chunk_size=batch_size, \n",
    "                                 max_retries=2, \n",
    "                                 retry_min_seconds= 60,\n",
    "                                 retry_max_seconds= 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43901586",
   "metadata": {},
   "outputs": [],
   "source": [
    "laws_index_name = \"srch-index-laws\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641f03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create Azure Search Vector-based Index\n",
    "# Setup the Payloads header\n",
    "headers = {'Content-Type': 'application/json','api-key': os.environ['AZURE_SEARCH_KEY']}\n",
    "params = {'api-version': os.environ['AZURE_SEARCH_API_VERSION']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7865d859",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_payload = {\n",
    "    \"name\": laws_index_name,\n",
    "    \"vectorSearch\": {\n",
    "        \"algorithms\": [  # We are showing here 3 types of search algorithms configurations that you can do\n",
    "             {\n",
    "                 \"name\": \"my-hnsw-config-1\",\n",
    "                 \"kind\": \"hnsw\",\n",
    "                 \"hnswParameters\": {\n",
    "                     \"m\": 4,\n",
    "                     \"efConstruction\": 400,\n",
    "                     \"efSearch\": 500,\n",
    "                     \"metric\": \"cosine\"\n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "                 \"name\": \"my-hnsw-config-2\",\n",
    "                 \"kind\": \"hnsw\",\n",
    "                 \"hnswParameters\": {\n",
    "                     \"m\": 8,\n",
    "                     \"efConstruction\": 800,\n",
    "                     \"efSearch\": 800,\n",
    "                     \"metric\": \"cosine\"\n",
    "                 }\n",
    "             },\n",
    "             {\n",
    "                 \"name\": \"my-eknn-config\",\n",
    "                 \"kind\": \"exhaustiveKnn\",\n",
    "                 \"exhaustiveKnnParameters\": {\n",
    "                     \"metric\": \"cosine\"\n",
    "                 }\n",
    "             }\n",
    "        ],\n",
    "        \"vectorizers\": [\n",
    "            {\n",
    "                \"name\": \"openai\",\n",
    "                \"kind\": \"azureOpenAI\",\n",
    "                \"azureOpenAIParameters\":\n",
    "                {\n",
    "                    \"resourceUri\" : os.environ['AZURE_OPENAI_ENDPOINT'],\n",
    "                    \"apiKey\" : os.environ['AZURE_OPENAI_API_KEY'],\n",
    "                    \"deploymentId\" : os.environ['EMBEDDING_DEPLOYMENT_NAME'],\n",
    "                    \"modelName\" : os.environ['EMBEDDING_DEPLOYMENT_NAME']\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"profiles\": [  # profiles is the diferent kind of combinations of algos and vectorizers\n",
    "            {\n",
    "             \"name\": \"my-vector-profile-1\",\n",
    "             \"algorithm\": \"my-hnsw-config-1\",\n",
    "             \"vectorizer\":\"openai\"\n",
    "            },\n",
    "            {\n",
    "             \"name\": \"my-vector-profile-2\",\n",
    "             \"algorithm\": \"my-hnsw-config-2\",\n",
    "             \"vectorizer\":\"openai\"\n",
    "            },\n",
    "            {\n",
    "             \"name\": \"my-vector-profile-3\",\n",
    "             \"algorithm\": \"my-eknn-config\",\n",
    "             \"vectorizer\":\"openai\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"semantic\": {\n",
    "        \"configurations\": [\n",
    "            {\n",
    "                \"name\": \"my-semantic-config\",\n",
    "                \"prioritizedFields\": {\n",
    "                    \"titleField\": {\n",
    "                        \"fieldName\": \"title\"\n",
    "                    },\n",
    "                    \"prioritizedContentFields\": [\n",
    "                        {\n",
    "                            \"fieldName\": \"chunk\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"prioritizedKeywordsFields\": []\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"fields\": [\n",
    "        {\"name\": \"id\", \"type\": \"Edm.String\", \"key\": \"true\", \"filterable\": \"true\" },\n",
    "        {\"name\": \"title\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
    "        {\"name\": \"chunk\",\"type\": \"Edm.String\",\"searchable\": \"true\",\"retrievable\": \"true\"},\n",
    "        {\"name\": \"name\", \"type\": \"Edm.String\", \"searchable\": \"true\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
    "        {\"name\": \"location\", \"type\": \"Edm.String\", \"searchable\": \"false\", \"retrievable\": \"true\", \"sortable\": \"false\", \"filterable\": \"false\", \"facetable\": \"false\"},\n",
    "        {\"name\": \"page_num\",\"type\": \"Edm.Int32\",\"searchable\": \"false\",\"retrievable\": \"true\"},\n",
    "        {\n",
    "            \"name\": \"chunkVector\",\n",
    "            \"type\": \"Collection(Edm.Single)\",\n",
    "            \"dimensions\": 3072,\n",
    "            \"vectorSearchProfile\": \"my-vector-profile-3\", # we picked profile 3 to show that this index uses eKNN vs HNSW (on prior notebooks)\n",
    "            \"searchable\": \"true\",\n",
    "            \"retrievable\": \"true\",\n",
    "            \"filterable\": \"false\",\n",
    "            \"sortable\": \"false\",\n",
    "            \"facetable\": \"false\"\n",
    "        }\n",
    "        \n",
    "    ],\n",
    "}\n",
    "\n",
    "r = requests.put(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + laws_index_name,\n",
    "                 data=json.dumps(index_payload), headers=headers, params=params)\n",
    "print(r.status_code)\n",
    "print(r.ok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78b0161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process a batch of pages\n",
    "def process_batch(bookname, pages):\n",
    "    try:\n",
    "        contents = [page[2] for page in pages]\n",
    "        chunk_vectors = embedder.embed_documents(contents)\n",
    "        \n",
    "        upload_payload = {\"value\": []}\n",
    "        for i, page in enumerate(pages):\n",
    "            page_num = page[0] + 1\n",
    "            content = page[2]\n",
    "            book_url = os.environ['BASE_CONTAINER_URL'] + bookname\n",
    "            \n",
    "            payload = {\n",
    "                \"@search.action\": \"upload\",\n",
    "                \"id\": str(uuid.uuid5(uuid.NAMESPACE_DNS, f\"{bookname}{page_num}\")),\n",
    "                \"title\": f\"{bookname}_page_{str(page_num)}\",\n",
    "                \"chunk\": content,\n",
    "                \"chunkVector\": chunk_vectors[i],\n",
    "                \"name\": bookname,\n",
    "                \"location\": book_url,\n",
    "                \"page_num\": page_num\n",
    "            }\n",
    "            upload_payload[\"value\"].append(payload)\n",
    "        \n",
    "        r = requests.post(os.environ['AZURE_SEARCH_ENDPOINT'] + \"/indexes/\" + laws_index_name + \"/docs/index\",\n",
    "                          data=json.dumps(upload_payload), headers=headers, params=params)\n",
    "        if r.status_code != 200:\n",
    "            print(f\"Failed to upload batch of pages from {bookname}: {r.status_code}\")\n",
    "            print(r.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Exception processing batch of pages from {bookname}: {e}\")\n",
    "        time.sleep(10)  # Wait before retrying\n",
    "        process_batch(bookname, pages)  # Retry the same batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0c9cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for bookname, bookmap in book_pages_map.items():\n",
    "        print(\"Uploading chunks from\", bookname)\n",
    "        # Split bookmap into chunks of size chunk_size\n",
    "        for i in tqdm(range(0, len(bookmap), batch_size)):\n",
    "            batch = bookmap[i:i + batch_size]\n",
    "            process_batch(bookname, batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec59020b",
   "metadata": {},
   "source": [
    "#### Query the Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7392263",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUESTION = \"Cuál es el primer artículo de la constitución?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe948c",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [laws_index_name]\n",
    "k=50 # in this index k corresponds to the top pages as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3858d369",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = CustomAzureSearchRetriever(indexes=[laws_index_name], topK=k, reranker_threshold=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65699251",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 2500\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT4oMINI_DEPLOYMENT_NAME\"], temperature=0.5, max_tokens=COMPLETION_TOKENS).configurable_alternatives(\n",
    "    ConfigurableField(id=\"model\"),\n",
    "    default_key=\"gpt4omini\",\n",
    "    gpt4o=AzureChatOpenAI(deployment_name=os.environ[\"GPT4o_DEPLOYMENT_NAME\"], temperature=0, max_tokens=COMPLETION_TOKENS),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a040e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOCSEARCH_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", DOCSEARCH_PROMPT_TEXT + \"\\n\\nCONTEXT:\\n{context}\\n\\n\"),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e62ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever, # Passes the question to the retriever and the results are assign to context\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | DOCSEARCH_PROMPT  # Passes the 4 variables above to the prompt template\n",
    "    | llm   # Passes the finished prompt to the LLM\n",
    "    | StrOutputParser()  # converts the output (Runnable object) to the desired output (string)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780ac4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in chain.with_config(configurable={\"model\": \"gpt4o\"}).stream(\n",
    "    {\"question\": QUESTION, \"language\": \"Spanish\"}):\n",
    "    print(chunk, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ccd563",
   "metadata": {},
   "source": [
    "### Step 2: Creating LangChain Tools\n",
    "\n",
    "To enable the AI agent to interact with our MCP servers, we must create LangChain tools. These tools act as intermediaries, sending HTTP requests to our Flask endpoints and fetching the responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7c994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Type, Optional\n",
    "from pydantic import BaseModel\n",
    "from langchain.tools import BaseTool, StructuredTool\n",
    "import requests\n",
    "import asyncio\n",
    "from langchain_core.callbacks import AsyncCallbackManagerForToolRun,CallbackManagerForToolRun\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Type\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class ReaderSearchInput(BaseModel):\n",
    "    query: str\n",
    "    \n",
    "\n",
    "class ReaderTool(BaseTool):\n",
    "    name: str = \"ReaderTool\"\n",
    "    description: str = \"Use this tool to search Argentine legal documents from Infoleg based on a query.\"\n",
    "    args_schema: Type[BaseModel] = ReaderSearchInput\n",
    "    \n",
    "    indexes: List[str] = [laws_index_name]\n",
    "    k: int = 50\n",
    "    reranker_th: float = 1\n",
    "\n",
    "    def _run(self, query: str,  return_direct = False, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "\n",
    "        retriever = CustomAzureSearchRetriever(indexes=self.indexes, topK=self.k, reranker_threshold=self.reranker_th, \n",
    "                                               callback_manager=self.callbacks)\n",
    "        results = retriever.invoke(input=query)\n",
    "        \n",
    "        return results\n",
    "\n",
    "    async def _arun(self, query: str, return_direct = False, run_manager: Optional[AsyncCallbackManagerForToolRun] = None) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        \n",
    "        retriever = CustomAzureSearchRetriever(indexes=self.indexes, topK=self.k, reranker_threshold=self.reranker_th, \n",
    "                                               callback_manager=self.callbacks)\n",
    "        loop = asyncio.get_event_loop()\n",
    "        results = await loop.run_in_executor(ThreadPoolExecutor(), retriever.invoke, query)\n",
    "        \n",
    "        return results\n",
    "\n",
    "\n",
    "class CriminalCodeTool(BaseTool):\n",
    "   \"\"\"Tool for fetching and returning the text content, image URLs, and links of the Argentina government web page, capped at a maximum number of words.\"\"\"\n",
    "   name: str = \"CriminalCodeTool\"\n",
    "   description: str = \"Use this tool to extract text or specific articles from the Código Penal Argentino hosted on Infoleg.\"\n",
    "   url: str = \"https://www.argentina.gob.ar/normativa/nacional/ley-11179-16546/texto\"\n",
    "   max_words: int = 10000\n",
    "   def _run(self) -> str:\n",
    "       \"\"\"Synchronously fetches the Argentina government web page and returns its text content, image URLs, and links capped at max_words.\"\"\"\n",
    "       try:\n",
    "           headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:90.0) Gecko/20100101 Firefox/90.0'}\n",
    "           response = requests.get(self.url, headers=headers, timeout=10)\n",
    "           response.raise_for_status()\n",
    "           soup = BeautifulSoup(response.content, 'html.parser')\n",
    "           # Extract text content\n",
    "           text_content = soup.get_text()\n",
    "           words = text_content.split()\n",
    "           capped_words = words[:self.max_words] if len(words) > self.max_words else words\n",
    "           text_result = ' '.join(capped_words)\n",
    "           \n",
    "           result = {\n",
    "               \"text_content\": text_result\n",
    "           }\n",
    "           \n",
    "           return json.dumps(result)\n",
    "       \n",
    "       except Exception as e:\n",
    "           return f\"Error fetching or parsing Infoleg page: {str(e)}\"\n",
    "   \n",
    "   async def _arun(self) -> str:\n",
    "       \"\"\"Asynchronously fetches a webpage and returns its text content, image URLs, and links capped at max_words.\"\"\"\n",
    "       loop = asyncio.get_event_loop()\n",
    "       try:\n",
    "           result = await loop.run_in_executor(ThreadPoolExecutor(), lambda: self._run())\n",
    "           return result\n",
    "       except Exception as e:\n",
    "           return json.dumps({\"error\": str(e)})\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6ecbec",
   "metadata": {},
   "source": [
    "### Step 3: Building the AI Agent with LangChain\n",
    "\n",
    "With our tools ready, we now integrate them into an Agent. The agent is built using the React agent pattern, allowing it to dynamically decide when and how to use our custom MCP tools to answer queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b974f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "def create_law_agent(llm: AzureChatOpenAI, prompt:str, name: str):\n",
    "    reader_tool = ReaderTool()\n",
    "    criminal_code_tool = CriminalCodeTool()\n",
    "    \n",
    "    law_agent = create_react_agent(\n",
    "        llm, \n",
    "        tools=[reader_tool, criminal_code_tool], \n",
    "        prompt=prompt,\n",
    "        name=name\n",
    "    )\n",
    "    \n",
    "    # Optional tagging for filtering or identification\n",
    "    law_agent = law_agent.with_config(tags=[name])\n",
    "    \n",
    "    return law_agent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4743ea",
   "metadata": {},
   "source": [
    "### Step 4: Testing the Law Agent\n",
    "\n",
    "Let's now test our Law Agent to verify that it correctly fetches data from the MCP tools and responds intelligently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4f8562",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import json\n",
    "import uuid\n",
    "import requests\n",
    "import logging\n",
    "import functools\n",
    "import operator\n",
    "from pydantic import BaseModel\n",
    "from typing import Annotated, Sequence, Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import AIMessage, HumanMessage, BaseMessage\n",
    "\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.checkpoint.serde.jsonplus import JsonPlusSerializer\n",
    "\n",
    "\n",
    "from common.cosmosdb_checkpointer import CosmosDBSaver, AsyncCosmosDBSaver\n",
    "\n",
    "#custom libraries that we will use later in the app\n",
    "from common.utils import (\n",
    "    create_docsearch_agent,\n",
    "    create_csvsearch_agent,\n",
    "    create_sqlsearch_agent,\n",
    "    create_websearch_agent,\n",
    "    create_apisearch_agent,\n",
    "    reduce_openapi_spec\n",
    ")\n",
    "\n",
    "from common.prompts import (\n",
    "    CUSTOM_CHATBOT_PREFIX,\n",
    "    DOCSEARCH_PROMPT_TEXT,\n",
    "    CSV_AGENT_PROMPT_TEXT,\n",
    "    MSSQL_AGENT_PROMPT_TEXT,\n",
    "    WEBSEARCH_PROMPT_TEXT,\n",
    "    APISEARCH_PROMPT_TEXT,\n",
    "    LEGAL_PROMPT_TEXT\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"credentials.env\")\n",
    "\n",
    "from IPython.display import Image, Markdown, Audio, display \n",
    "\n",
    "from common.audio_utils import text_to_speech \n",
    "\n",
    "def play_audio(file_path):\n",
    "    \"\"\"Play an audio file in Jupyter Notebook.\"\"\"\n",
    "    display(Audio(file_path, autoplay=True))\n",
    "\n",
    "def printmd(string):\n",
    "    # Remove ```markdown and ``` from the text\n",
    "    clean_content = re.sub(r'^```markdown\\n', '', string)\n",
    "    clean_content = re.sub(r'^```\\n', '', clean_content)\n",
    "    clean_content = re.sub(r'\\n```$', '', clean_content)\n",
    "\n",
    "    # Escape dollar signs to prevent LaTeX rendering\n",
    "    clean_content = clean_content.replace('$', r'\\$')\n",
    "    display(Markdown(clean_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643d1650-6416-46fd-8b21-f5fb298ec063",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "COMPLETION_TOKENS = 5000\n",
    "\n",
    "llm = AzureChatOpenAI(deployment_name=os.environ[\"GPT4o_DEPLOYMENT_NAME\"], \n",
    "                      temperature=0, max_tokens=COMPLETION_TOKENS, \n",
    "                      streaming=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b56a94-0471-41c3-b441-3a73ff5dedfc",
   "metadata": {},
   "source": [
    "#### Creating all of the Specialized Agents to use with the Supervisor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fab607e-898c-4e71-9c53-b0231f179fcc",
   "metadata": {},
   "source": [
    "#### **Law Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43c4f74-2fdc-467d-8d72-3fba46699957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "law_agent = create_law_agent(llm, prompt=CUSTOM_CHATBOT_PREFIX + LEGAL_PROMPT_TEXT,\n",
    "                                     name=\"LawSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d54f7b8",
   "metadata": {},
   "source": [
    "#### **DocSearch Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7117b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [\"srch-index-files\", \"srch-index-csv\", \"srch-index-books\"]\n",
    "docsearch_agent = create_docsearch_agent(llm,indexes,k=20,reranker_th=1.5,\n",
    "                                         prompt=CUSTOM_CHATBOT_PREFIX + DOCSEARCH_PROMPT_TEXT,\n",
    "                                         sas_token=os.environ['BLOB_SAS_TOKEN'],\n",
    "                                         name=\"DocSearch\"\n",
    "                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5160190b",
   "metadata": {},
   "source": [
    "#### **CSVSearch Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e30745",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"./data/all-states-history.csv\"\n",
    "csvsearch_agent = create_csvsearch_agent(llm,\n",
    "                                         prompt=CUSTOM_CHATBOT_PREFIX + CSV_AGENT_PROMPT_TEXT.format(file_url=file_url),\n",
    "                                         name=\"CSVSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292a3eca",
   "metadata": {},
   "source": [
    "#### **SQLSearch Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f4a28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlsearch_agent = create_sqlsearch_agent(llm, \n",
    "                                     prompt=CUSTOM_CHATBOT_PREFIX + MSSQL_AGENT_PROMPT_TEXT,\n",
    "                                     name=\"SQLSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317dea9a",
   "metadata": {},
   "source": [
    "#### **WebSearch Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7455f019",
   "metadata": {},
   "outputs": [],
   "source": [
    "websearch_agent = create_websearch_agent(llm, \n",
    "                                     prompt=CUSTOM_CHATBOT_PREFIX + WEBSEARCH_PROMPT_TEXT,\n",
    "                                     name=\"WebSearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e462b3",
   "metadata": {},
   "source": [
    "#### **APISearch Agent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e929c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_file_path = \"./data/openapi_kraken.json\"\n",
    "with open(api_file_path, 'r') as file:\n",
    "    spec = json.load(file)\n",
    "    \n",
    "reduced_api_spec = reduce_openapi_spec(spec)\n",
    "\n",
    "apisearch_agent = create_apisearch_agent(llm, \n",
    "                                     prompt=CUSTOM_CHATBOT_PREFIX + APISEARCH_PROMPT_TEXT.format(api_spec=reduced_api_spec),\n",
    "                                     name=\"APISearch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae745320-0c99-4619-a072-93f306907a09",
   "metadata": {},
   "source": [
    "#### Helper Print and Audio Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40c5f0e-b6b5-49e4-8170-e80419b71dca",
   "metadata": {},
   "source": [
    "Define functions to print the events and respond with Audio.\n",
    "\n",
    "These are two different ways to print and stream the answers and events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb7138-a982-460a-9522-97768bce5a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define a sync function to stream graph updates\n",
    "def stream_graph_updates_sync(user_input: str, graph, config):\n",
    "    last_agent_message = \"\"  # Will hold the latest AIMessage content\n",
    "\n",
    "    for event in graph.stream({\"messages\": [(\"human\", user_input)]}, config, stream_mode=\"updates\"):\n",
    "        # print(event)  # Print the raw event (keep this for debugging if needed)\n",
    "\n",
    "        # Each event is a dict, e.g. {\"WebSearchAgent\": {...}} or {\"supervisor\": {\"messages\": [...]}}\n",
    "        if isinstance(event, dict):\n",
    "            for key, value in event.items():\n",
    "                # If this is an agent or supervisor event, store the latest message content\n",
    "                # (No change here—this correctly captures all updates, with the final one being the supervisor's response)\n",
    "                if isinstance(value, dict) and \"messages\" in value:\n",
    "                    messages = value[\"messages\"]\n",
    "                    if messages:\n",
    "                        last_msg = messages[-1]\n",
    "                        # Only update last_agent_message if it's an AIMessage with content\n",
    "                        # (Added this check to avoid overwriting with intermediate ToolMessages or empty contents;\n",
    "                        # ensures we prioritize AIMessages, which are the actual responses)\n",
    "                        if hasattr(last_msg, 'content') and last_msg.content and not getattr(last_msg, 'tool_calls', None):\n",
    "                            last_agent_message = last_msg.content\n",
    "\n",
    "    # It triggers after all events, using the final last_agent_message (supervisor's response)\n",
    "    if last_agent_message:\n",
    "        print(last_agent_message)\n",
    "        tts_audio_file = text_to_speech(last_agent_message)\n",
    "        if tts_audio_file:\n",
    "            play_audio(tts_audio_file)\n",
    "\n",
    "\n",
    "\n",
    "# Define an async function to stream events async\n",
    "async def stream_graph_updates_async(user_input: str, graph, config, exclude_tags_list=[] ):\n",
    "    inputs = {\"messages\": [(\"human\", user_input)]}\n",
    "    complete_text = \"\"  # Store the full response text for TTS\n",
    "    if config is None:\n",
    "        config = {}\n",
    "\n",
    "    async for event in graph.astream_events(inputs, config, exclude_tags=exclude_tags_list, version=\"v2\"):\n",
    "        # print(event)\n",
    "        \n",
    "        # Added: Reset complete_text on each chat model start from the 'agent' node\n",
    "        # This ensures complete_text only holds the output from the most recent model call,\n",
    "        # which will be the final supervisor response at the end of processing\n",
    "        if (\n",
    "            event[\"event\"] == \"on_chat_model_start\"\n",
    "            and event[\"metadata\"].get(\"langgraph_node\") == \"agent\"\n",
    "        ):\n",
    "            # print(event)\n",
    "            complete_text = \"\"\n",
    "        \n",
    "        if (\n",
    "            event[\"event\"] == \"on_chat_model_stream\"  # Ensure the event is a chat stream event\n",
    "            and event[\"metadata\"].get(\"langgraph_node\") == \"agent\"\n",
    "        ):\n",
    "            # Print the content of the chunk progressively\n",
    "            chunk_text = event[\"data\"][\"chunk\"].content\n",
    "            print(chunk_text, end=\"\", flush=True)\n",
    "            complete_text += chunk_text  # Accumulate chunks of text\n",
    "\n",
    "        if (\n",
    "            event[\"event\"] == \"on_tool_start\"  \n",
    "            and event[\"metadata\"].get(\"langgraph_node\") == \"tools\"  # Ensure it's from the tools node\n",
    "        ):\n",
    "            print(\"\\n--\")\n",
    "            print(f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\")\n",
    "            print(\"--\")\n",
    "        if (\n",
    "            event[\"event\"] == \"on_tool_end\"  # Ensure the event is a chat stream event\n",
    "            and event[\"metadata\"].get(\"langgraph_node\") == \"tools\"  # Ensure it's from the chatbot node\n",
    "        ):\n",
    "            print(\"\\n--\")\n",
    "            print(f\"Done tool: {event['name']}\")\n",
    "            print(\"--\")\n",
    "            \n",
    "    # Moved TTS here, outside the loop (key fix: triggers after all events, using the final accumulated complete_text)\n",
    "    # Removed the 'next' == 'FINISH' check, as it's not present in events and unnecessary\n",
    "    if complete_text:\n",
    "        tts_audio_file = text_to_speech(complete_text)\n",
    "        if tts_audio_file:\n",
    "            play_audio(tts_audio_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83664e6f-6995-4584-80d0-f4424647944b",
   "metadata": {},
   "source": [
    "#### Create supervisor with `langgraph-supervisor`\n",
    "\n",
    "To implement out multi-agent system, we will use [`create_supervisor`]from the prebuilt `langgraph-supervisor` library:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a952b2-7dc2-4e8d-9186-f63c7c057236",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langgraph_supervisor import create_supervisor\n",
    "\n",
    "supervisor = create_supervisor(\n",
    "    model=llm,\n",
    "    agents=[law_agent, docsearch_agent, csvsearch_agent, websearch_agent, apisearch_agent],\n",
    "    prompt=(\n",
    "        \"You are a supervisor managing several agents:\\n\"\n",
    "        \"- a LawSearch agent. Assign tasks to this agent if the user states: @weathersearch.\\n\"\n",
    "        \"- a DocSearch agent. Assign tasks to this agent if the user states: @docsearch.\\n\"\n",
    "        \"- a CSVSearch agent. Assign tasks to this agent if the user states: @csvsearch.\\n\"\n",
    "        \"- a WebSearch agent. Assign tasks to this agent if the user states: @websearch.\\n\"\n",
    "        \"- a ApiSearch agent. Assign tasks to this agent if the user states: @apisearch.\\n\"\n",
    "        \"Assign work to one agent at a time, do not call agents in parallel.\\n\"\n",
    "        \"Do not do any work yourself.\"\n",
    "    ),\n",
    "    add_handoff_back_messages=True,\n",
    "    output_mode=\"full_history\",\n",
    ")\n",
    "\n",
    "checkpointer_sync = CosmosDBSaver(\n",
    "    endpoint=os.environ[\"AZURE_COSMOSDB_ENDPOINT\"],\n",
    "    key=os.environ[\"AZURE_COSMOSDB_KEY\"],\n",
    "    database_name=os.environ[\"AZURE_COSMOSDB_NAME\"],\n",
    "    container_name=os.environ[\"AZURE_COSMOSDB_CONTAINER_NAME\"],\n",
    "    serde=JsonPlusSerializer(),\n",
    ")\n",
    "\n",
    "# Manually initialize resources\n",
    "checkpointer_sync.setup()\n",
    "\n",
    "# Compile the synchronous graph after setup is complete\n",
    "graph_sync = supervisor.compile(checkpointer=checkpointer_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3141a-6715-4bcd-aea1-aeebec6e4827",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uuid\n",
    "# Define a test thread_id to store in the persistent storage\n",
    "config_sync = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "display(Image(graph_sync.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a7d1f9-da7d-4272-b3d2-b9c6dc91fb8e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Run SYNC App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5aacd7-c6ea-4928-bcc2-b145a50019a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run the synchronous agent\n",
    "print(\"Running the synchronous agent:\")\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    try:\n",
    "        stream_graph_updates_sync(user_input, graph_sync, config_sync)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during synchronous update: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a17c25-7a0c-4d25-8901-cc582cac89bf",
   "metadata": {},
   "source": [
    "### Construct the ASYNC graph of our application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4904a07d-b857-45d7-86ac-c7cade3e9080",
   "metadata": {},
   "source": [
    "#### Let's talk to our Engine ASYNC chat bot now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc9ed91-53f4-445c-83f4-663aee407183",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can as well avoid the .setup() call of the cosmosDB by using the with statement as below\n",
    "async def run_async_agent():\n",
    "    async with AsyncCosmosDBSaver(\n",
    "        endpoint=os.environ[\"AZURE_COSMOSDB_ENDPOINT\"],\n",
    "        key=os.environ[\"AZURE_COSMOSDB_KEY\"],\n",
    "        database_name=os.environ[\"AZURE_COSMOSDB_NAME\"],\n",
    "        container_name=os.environ[\"AZURE_COSMOSDB_CONTAINER_NAME\"],\n",
    "        serde=JsonPlusSerializer(),\n",
    "    ) as checkpointer_async:\n",
    "        # Compile the asynchronous graph\n",
    "        graph_async = supervisor.compile(checkpointer=checkpointer_async)\n",
    "        # Define a test thread_id to store in the persistent storage\n",
    "        config_async = {\"configurable\": {\"thread_id\": str(uuid.uuid4())}}\n",
    "\n",
    "\n",
    "\n",
    "        print(\"\\nRunning the asynchronous agent:\")\n",
    "        while True:\n",
    "            user_input = input(\"User: \")\n",
    "            if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "                print(\"Goodbye!\")\n",
    "                break\n",
    "            await stream_graph_updates_async(user_input, graph_async ,config_async, exclude_tags_list=[\"WeatherSearch\"])\n",
    "\n",
    "# Run the asynchronous agent\n",
    "await run_async_agent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
